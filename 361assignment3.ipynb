{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fab662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib.colors import ListedColormap\n",
    "<<<<<<< local\n",
    "=======\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    ">>>>>>> remote\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933b33c",
   "metadata": {},
   "source": [
    "# Task One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93396f41",
   "metadata": {},
   "source": [
    "## 1(a) Loading data & constructing feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97b2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of articles: 428\n",
      "number of extracted features: 13518\n",
      "\n",
      "5 example articles with their extracted features:\n",
      "   00  000  000th  001st  0051  007  0100  0130  028  05  ...  zola  zombie  \\\n",
      "0   0    1      0      0     0    0     0     0    0   0  ...     0       0   \n",
      "1   0    0      0      0     0    0     0     0    0   0  ...     0       0   \n",
      "2   0    0      0      0     0    0     0     0    0   0  ...     0       0   \n",
      "3   0    0      0      0     0    0     0     0    0   0  ...     0       0   \n",
      "4   0    0      0      0     0    0     0     0    0   0  ...     0       0   \n",
      "\n",
      "   zombies  zone  zonealarm  zones  zoom  zooms  zooropa  zorro  \n",
      "0        0     0          0      0     0      0        0      0  \n",
      "1        0     0          0      0     0      0        0      0  \n",
      "2        0     0          0      0     0      0        0      0  \n",
      "3        0     0          0      0     0      0        0      0  \n",
      "4        0     0          0      0     0      0        1      0  \n",
      "\n",
      "[5 rows x 13518 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\")\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['Text'])\n",
    "\n",
    "print(f\"number of articles: {X.shape[0]}\")\n",
    "print(f\"number of extracted features: {X.shape[1]}\\n\")\n",
    "\n",
    "example_df = pd.DataFrame(\n",
    "    X[:5].toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "print(\"5 example articles with their extracted features:\")\n",
    "print(example_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d1192",
   "metadata": {},
   "source": [
    "## 1(b) Term Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075274a3-35c8-497f-a3af-a64c38a5e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,10))\n",
    "total_word = (' '.join(df['Text'])).split()\n",
    "frequency = Counter(total_word).most_common(50)\n",
    "plt.bar([w[0] for w in frequency],[w[1] for w in frequency])\n",
    "plt.title(\"top-50 term frequency distribution\")\n",
    "plt.ylabel('frequency')\n",
    "plt.show()\n",
    "\n",
    "label = ['entertainment','tech']\n",
    "for l in label:\n",
    "    plt.figure(figsize=(21,5))\n",
    "    total_text = (' '.join(df[df['Category'] == l]['Text'])).split()\n",
    "    frequency = Counter(total_text).most_common(25)\n",
    "    plt.bar([w[0] for w in frequency],[w[1] for w in frequency])\n",
    "    plt.title(f\"top-25 term frequency distribution in Category {l}\")\n",
    "    plt.ylabel('frequency')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "df['Category'].value_counts().plot(kind = 'bar')\n",
    "plt.title('Class distribution')\n",
    "plt.ylabel('number of articles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97894b36",
   "metadata": {},
   "source": [
    "# Task Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920c218",
   "metadata": {},
   "source": [
    "## 2(a) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8a881-be1e-4af0-ab0b-813007b299eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 words that most likely to occurr\n",
      "Category entertainment: ['said', 'film', 'best', 'year', 'music', 'also', 'us', 'new', 'one', 'show', 'first', 'awards', 'tv', 'uk', 'last', 'actor', 'number', 'band', 'mr', 'star']\n",
      "Category tech: ['said', 'people', 'new', 'mobile', 'mr', 'one', 'also', 'would', 'could', 'technology', 'use', 'users', 'net', 'software', 'games', 'us', 'music', 'many', 'year', 'phone']\n",
      "\n",
      "\n",
      "Top-20 words that maximize the quantity\n",
      "Category entertainment: ['actress', 'singer', 'oscar', 'stars', 'aviator', 'band', 'nominated', 'rock', 'festival', 'album', 'nominations', 'charles', 'chart', 'foxx', 'oscars', 'starring', 'singles', 'jamie', 'swank', 'comedy']\n",
      "Category tech: ['users', 'software', 'microsoft', 'mobile', 'broadband', 'virus', 'firms', 'pc', 'spam', 'phones', 'gadget', 'net', 'consumer', 'mobiles', 'gadgets', 'windows', 'machines', 'technologies', 'systems', 'device']\n"
     ]
    }
   ],
   "source": [
    "y = df['Category']\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "nb_all_data = MultinomialNB()\n",
    "nb_all_data.fit(X,y)\n",
    "\n",
    "logprob = nb_all_data.feature_log_prob_\n",
    "prob = np.exp(logprob)\n",
    "classes = enumerate(nb_all_data.classes_)\n",
    "\n",
    "#(i)\n",
    "print('Top-20 words that most likely to occurr')\n",
    "for index, cla in classes:\n",
    "    indice = np.argsort(-prob[index])[:20]\n",
    "    word = words[indice]\n",
    "    print(f\"Category {cla}: {list(word)}\")\n",
    "print('\\n')\n",
    "\n",
    "#(ii)\n",
    "print('Top-20 words that maximize the quantity')\n",
    "classes = enumerate(nb_all_data.classes_)\n",
    "for index, cla in classes:\n",
    "    p_Yequaly = logprob[index]\n",
    "    p_Ynotequaly = logprob[1-index]\n",
    "    logratio = p_Yequaly - p_Ynotequaly\n",
    "\n",
    "    ratio = np.exp(logratio)\n",
    "    indice = np.argsort(-ratio)[:20]\n",
    "    word = words[indice]\n",
    "    print(f\"Category {cla}: {list(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be97ef",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The list of the top 20 words that maximise the P(Xw = 1|Y = y)/P(Xw = 1|Y != y) describes the two classes better. The list in (i) only displays words that appear frequently in different categories, which contain many meaningless and commonly used words. These common words will appear in both categories, for example, 'said' appears in both categories in list (i). At the same time, the list in (ii) highlights the probability of words that appear frequently in only one category, while reducing the probability of common words that appear in both categories. Most of the words in list (ii) have marked features of the specific category. Therefore, the list in (ii) describes the two classes better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f14dca",
   "metadata": {},
   "source": [
    "## 2(b) kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN code goes here\n",
    "\n",
    "# y = df['Category']\n",
    "# knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "# knn_classifier.fit(X, y)\n",
    "\n",
    "# Using k = 5 and Manhattan distance \n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric='manhattan', p=1)\n",
    "\n",
    "# Fit \n",
    "knn.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn surface plot\n",
    "\n",
    "# Reduce dimensionality to 2D for visualization\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_2d = svd.fit_transform(X)\n",
    "\n",
    "# Define 2D grid over the projected data space\n",
    "h = 0.05  # step size for grid\n",
    "x_min, x_max = X_2d[:, 0].min() - h, X_2d[:, 0].max() + h*10\n",
    "y_min, y_max = X_2d[:, 1].min() - h, X_2d[:, 1].max() + h*10\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "#Encode string labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "#Train kNN classifier using 2D features\n",
    "knn.fit(X_2d, y_encoded)\n",
    "\n",
    "# Predict labels over the grid\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = knn.predict(grid_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "# Plot decision surface and original data points\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.4)  # decision boundary\n",
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_encoded, cmap=plt.cm.coolwarm, edgecolors='k')  # data points\n",
    "plt.title(\"KNN Decision Boundary (k=5, metric=manhattan)\")\n",
    "plt.xlabel(\"SVD Component 1\")\n",
    "plt.ylabel(\"SVD Component 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Zoomed-in version: focus on region where most points cluster\n",
    "x_min, x_max = 0, 15\n",
    "y_min, y_max = -5, 15\n",
    "h = 0.05\n",
    "\n",
    "# Generate the grid\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class for each grid point\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = knn.predict(grid_points)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot zoomed-in decision surface\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.4)\n",
    "plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_encoded, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "plt.title(\"Zoomed-in KNN Decision Boundary (k=5, metric=manhattan)\")\n",
    "plt.xlabel(\"SVD Component 1\")\n",
    "plt.ylabel(\"SVD Component 2\")\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 15)\n",
    "plt.ylim(-5, 15)\n",
    "\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935f52c0",
   "metadata": {},
   "source": [
    "To visualize the decision boundary of my kNN classifier, we used SVD to reduce the high-dimensional text feature vectors to two components. The surface plot above shows the predicted class regions using k=5 and Manhattan distance.\n",
    "\n",
    "The first surface plot shows the overall decision boundary. From this full view, we noticed that most data points are clustered within a small region, roughly between SVD component 1 = [0, 15] and component 2 = [0, 15]. To better analyze the boundary behavior in the most informative area, we generated a zoomed-in version focusing on that region.\n",
    "\n",
    "In the zoomed-in plot, the decision boundary appears relatively smooth, with clear separation between the two classes. A smaller k (e.g., k=1) would create very jagged, overfitted boundaries that conform too closely to the training data. In contrast, a larger k would produce overly smoothed boundaries that might ignore local structure. \n",
    "\n",
    "We also observe that the Manhattan distance metric tends to produce more “boxy” decision boundaries. If we were to use Euclidean distance, the boundary would likely be smoother. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b5e0fb",
   "metadata": {},
   "source": [
    "## 2(c) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM code goes here\n",
    "\n",
    "if hasattr(X, \"toarray\"):\n",
    "    X_dense = X.toarray().astype(np.float64)\n",
    "else:\n",
    "    X_dense = np.asarray(X, dtype=np.float64)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)   # y_enc categorised to 0 and 1\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_2d_svm = svd.fit_transform(X_dense)\n",
    "\n",
    "\n",
    "C_soft = 1.0  # adjust\n",
    "svm_linear = SVC(kernel='linear', C=C_soft, random_state=42)\n",
    "svm_linear.fit(X_2d_svm, y_enc)\n",
    "\n",
    "\n",
    "gamma_rbf = 0.5  # adjust\n",
    "C_hard = 1e3     # incr c to approximate \"hard margin\"\n",
    "svm_rbf = SVC(kernel='rbf', C=C_hard, gamma=gamma_rbf, random_state=42)\n",
    "svm_rbf.fit(X_2d_svm, y_enc)\n",
    "\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, title):\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                         np.linspace(y_min, y_max, 300))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=plt.cm.coolwarm)\n",
    "    plt.xlabel('SVM Component 1')\n",
    "    plt.ylabel('SVM Component 2')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot soft-margin linear SVM\n",
    "plot_decision_boundary(svm_linear, X_2d_svm, y_enc, f\"Soft-margin Linear SVM (C={C_soft})\")\n",
    "\n",
    "# plot hard-margin RBF SVM\n",
    "plot_decision_boundary(svm_rbf, X_2d_svm, y_enc, f\"Hard-margin RBF SVM (C={C_hard}, gamma={gamma_rbf})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86850ae4",
   "metadata": {},
   "source": [
    "Visually we can see that our data seems fairly linearly seperable, as such we would expect our kernel hyperparameter to be better as linear than rbf, if not comparable. As our C hyperparamter increases our decision boundaries become much harder, approaching a hard margin svm, while lower values of C will mean that our model punishes misclassifications much less which typically results in much better generalisation, but also risks underfitting. At C=1 we see that our model allows for some misclassification but results in what we would expect to be a much more generalisable model than our hard margin model (the hard margin is achieved by increasing C to 1000)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da0ed05",
   "metadata": {},
   "source": [
    "## 2(d) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "=======\n",
    ">>>>>>> remote\n",
    "hidden_units = [5,20,40]\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "entropy_losses =[]\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=42) #fitting to 2d view\n",
    "X_2d = svd.fit_transform(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) # y_enc categorised to 0 and 1\n",
    "\n",
    "for unit in hidden_units: #training NN classifier with hidden units\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(unit,), max_iter=epochs, random_state=42)\n",
    "    classifier.fit(X_2d,y_encoded)\n",
    "\n",
    "    entropy_loss = classifier.loss_\n",
    "    entropy_losses.append(entropy_loss)\n",
    "\n",
    "plt.figure(figsize=(7, 5)) #plotting entropy loss\n",
    "plt.plot(hidden_units, entropy_losses, marker='o')\n",
    "plt.title(\"Training Cross-Entropy Loss vs Number of Hidden Units\")\n",
    "plt.xlabel(\"Number of Hidden Units\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c337ea",
   "metadata": {},
   "source": [
    "As shown in the graph above, as the number of hidden units increases, the cross-entropy loss decreases. \n",
    "This suggests that the larger the number of hidden units, the more accurately the neural network can fit into the training data.\n",
    "This means that the entropy loss for the training data will decrease. However, there is a danger of overfitting the training data, which can result in long-term losses of prediction accuracy. \n",
    "Considering this and the dimensioning returns comparing 20 hidden units to 40, I believe that using 20 hidden units is appropriate for training and evaluating the prediction accuracy of the testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b4b6e0",
   "metadata": {},
   "source": [
    "# Task Three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a6cc1",
   "metadata": {},
   "source": [
    "## 3(a) F1 Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5d70f",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "mlist = [0.1,0.3,0.5,0.7,0.9]\n",
    "train_f1_score = []\n",
    "test_f1_score = []\n",
    "total_article = X.shape[0]\n",
    "for m in mlist:\n",
    "    X_train = X[0:int(m * total_article)]\n",
    "    y_train = y[0:int(m * total_article)]\n",
    "    X_test = X[int(m * total_article):]\n",
    "    y_test = y[int(m * total_article):]\n",
    "    nbmodel =  MultinomialNB()\n",
    "    nbmodel.fit(X_train, y_train)\n",
    "    train_predict = nbmodel.predict(X_train)\n",
    "    train_f1 = f1_score(y_train, train_predict, pos_label = label[1])\n",
    "    train_f1_score.append(train_f1)\n",
    "    test_predict = nbmodel.predict(X_test)\n",
    "    test_f1 = f1_score(y_test, test_predict, pos_label = label[1])\n",
    "    test_f1_score.append(test_f1)\n",
    "#(i)    \n",
    "plt.plot(mlist, train_f1_score)\n",
    "plt.xlabel(\"values of m\")\n",
    "plt.ylabel(\"F1 scores of train data in naive bayes\")\n",
    "plt.show()\n",
    "#(ii)\n",
    "plt.plot(mlist, test_f1_score)\n",
    "plt.xlabel(\"values of m\")\n",
    "plt.ylabel(\"F1 scores of test data in naive bayes\")\n",
    "plt.show()\n",
    "\n",
    "# Keep all code for the other classifiers in this cell so that all the plots display together.\n",
    "# Probably modify the above to generate all the plots together. Or maybe chuck in a bunch of functions so the variable names don't mess each other up?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab43bd",
   "metadata": {},
   "source": [
    "### Naive Bayes Discussion\n",
    "For low m (m = 0.1, m = 0.3), the F1 score of training data is very high, and the F1 score of testing data increases rapidly from a relatively low value. When the training data set increases from a very small set, the prediction of the testing data is trending to have increasing accuracy. As the training data set is still very small, it is very easy for the model to make the correct prediction on the training data.\n",
    "For middle m (m from 0.3 to 0.5), the F1 score of training data decreases from a very high value to a relatively high value, and the F1 score of testing data increases more slowly to a relatively high value. As the training data set increases, it has relatively lower accuracy when making predictions on the training data as it tends to be less overfitting on training data as the size of training data set increases, and the accuracy of predictions on test data increases when the size of the training data set increases.\n",
    "For large m, the F1 score of testing data grows very high, and the F1 score of training data is still high, but relatively lower than for small m. The F1 scores for the training data and testing data are similar, which shows that the model gives high accuracy in both the training data and the testing data when m is large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4dc11f",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e668dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "mlist = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "train_f1_score = []\n",
    "test_f1_score = []\n",
    "\n",
    "total_article = X.shape[0]\n",
    "\n",
    "for m in mlist:\n",
    "    m_size = int(m * total_article)\n",
    "    X_train = X[:m_size]\n",
    "    y_train = y[:m_size]\n",
    "    X_test = X[m_size:]\n",
    "    y_test = y[m_size:]\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = knn.predict(X_train)\n",
    "    f1_train = f1_score(y_train, y_train_pred, pos_label = label[1])\n",
    "    train_f1_score.append(f1_train)\n",
    "\n",
    "    y_test_pred = knn.predict(X_test)\n",
    "    f1_test = f1_score(y_test, y_test_pred, pos_label = label[1])\n",
    "    test_f1_score.append(f1_test)\n",
    "\n",
    "plt.plot(mlist, train_f1_score)\n",
    "plt.xlabel(\"Training Portion (m)\")\n",
    "plt.ylabel(\"Train F1 Score (KNN)\")\n",
    "plt.title(\"Train F1 vs Proportion of Training Data (KNN)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(mlist, test_f1_score, color='orange')\n",
    "plt.xlabel(\"Training Portion (m)\")\n",
    "plt.ylabel(\"Test F1 Score (KNN)\")\n",
    "plt.title(\"Test F1 Score vs Proportion of Training Data (KNN)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(mlist, train_f1_score, label='Train F1')\n",
    "plt.plot(mlist, test_f1_score, label='Test F1', color='orange')\n",
    "plt.xlabel(\"Training Set Proportion (m)\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"Train and Test F1 Score vs Training Set Size (KNN)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd201d07",
   "metadata": {},
   "source": [
    "As shown in the plot, both training and testing F1 scores increase as the proportion of training data (m) increases. The training F1 improves steadily, reaching over 0.7 when using 90% of the data, while the testing F1 also improves but remains significantly lower than the training F1 throughout.\n",
    "\n",
    "This growing gap between training and testing performance suggests a degree of overfitting: the model fits the training data well but generalizes less effectively to unseen data, especially when the training set is small. However, the trend also indicates that more training data consistently leads to better generalization, as seen by the steady rise in test F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be16de",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "# Task 3(a)\n",
    "=======\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "mlist = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "train_f1_linear = []\n",
    "test_f1_linear = []\n",
    "train_f1_rbf = []\n",
    "test_f1_rbf = []\n",
    "\n",
    "total_n = X_2d_svm.shape[0]\n",
    "\n",
    "for m in mlist:\n",
    "    mN = int(m * total_n)\n",
    "    X_train = X_2d_svm[:mN]\n",
    "    y_train = y_enc[:mN]\n",
    "    X_test = X_2d_svm[mN:]\n",
    "    y_test = y_enc[mN:]\n",
    "\n",
    "    # Linear SVM\n",
    "    svm_linear = SVC(kernel='linear', C=C_soft, random_state=37)\n",
    "    svm_linear.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = svm_linear.predict(X_train)\n",
    "    y_test_pred = svm_linear.predict(X_test)\n",
    "\n",
    "    train_f1_linear.append(f1_score(y_train, y_train_pred))\n",
    "    test_f1_linear.append(f1_score(y_test, y_test_pred))\n",
    "\n",
    "    # RBF SVM\n",
    "    svm_rbf = SVC(kernel='rbf', C=C_hard, gamma=gamma_rbf, random_state=37)\n",
    "    svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred_rbf = svm_rbf.predict(X_train)\n",
    "    y_test_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "    train_f1_rbf.append(f1_score(y_train, y_train_pred_rbf))\n",
    "    test_f1_rbf.append(f1_score(y_test, y_test_pred_rbf))\n",
    "\n",
    "\n",
    "plt.plot(mlist, train_f1_linear, label='Linear')\n",
    "plt.plot(mlist, train_f1_rbf, label='RBF')\n",
    "plt.xlabel(\"values of m\")\n",
    "plt.ylabel(\"F1 scores of train data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(mlist, test_f1_linear, label='Linear')\n",
    "plt.plot(mlist, test_f1_rbf, label='RBF')\n",
    "plt.xlabel(\"values of m\")\n",
    "plt.ylabel(\"F1 scores of test data\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979dd8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6f18073",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "m_list = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "total_article = X.shape[0]\n",
    "\n",
    "for m in m_list:\n",
    "    m_size = int(m * total_article)\n",
    "    X_train = X[:m_size]\n",
    "    y_train = y[:m_size]\n",
    "    X_test = X[m_size:]\n",
    "    y_test = y[m_size:]\n",
    "\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(20,), max_iter=100, random_state=42)\n",
    "    classifier.fit(X_train,y_train)\n",
    "\n",
    "    y_training_prediction = classifier.predict(X_train)\n",
    "    y_testing_prediction = classifier.predict(X_test)\n",
    "\n",
    "    train_score = f1_score(y_train, y_training_prediction, pos_label = label[1])\n",
    "    test_score = f1_score(y_test, y_testing_prediction, pos_label = label[1])\n",
    "\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(m_list, train_scores, label='Train F Score')\n",
    "plt.plot(m_list, test_scores, label='Test F Score')\n",
    "plt.title(\"F Score vs Training Set Size\")\n",
    "plt.xlabel(\"Training Data Fraction\")\n",
    "plt.ylabel(\"F-Score\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "=======\n",
    "# neurel net here\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974082f3",
   "metadata": {},
   "source": [
    "## 3(b) Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f595a1",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4038831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is 0.1 with an accuracy of 0.9860191518467852\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "alpha_values = [0.1 * x for x in range(1,51)]\n",
    "accuracy_score_ = []\n",
    "\n",
    "for a in alpha_values:\n",
    "    model_cv = MultinomialNB(alpha = a)\n",
    "    score = cross_val_score(model_cv, X, y, cv = 5, scoring = 'accuracy')\n",
    "    accuracy_score_.append(np.mean(score))\n",
    "\n",
    "    \n",
    "best_alpha_index = accuracy_score_.index(max(accuracy_score_))\n",
    "best_alpha = alpha_values[best_alpha_index]\n",
    "print(f\"Best alpha value is {best_alpha} with an accuracy of {max(accuracy_score_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ae4dc",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The hyperparameter alpha is used in Laplace smoothing, it controls how sensitive the model is towards the rare features. A model with a small alpha value will be more sensitive towards rare features. In this question, as the two categories have very different articles, a small alpha value of 0.1 gives the best accuracy in testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d01958",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48742a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "k_range = range(1, 20)\n",
    "acc_euclidean = []\n",
    "acc_manhattan = []\n",
    "\n",
    "for k in k_range:\n",
    "\n",
    "    knn_eu = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
    "    knn_eu.fit(X_train, y_train)\n",
    "    y_pred_eu = knn_eu.predict(X_test)\n",
    "    acc_euclidean.append(accuracy_score(y_test, y_pred_eu))\n",
    "\n",
    "    knn_man = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=1)\n",
    "    knn_man.fit(X_train, y_train)\n",
    "    y_pred_man = knn_man.predict(X_test)\n",
    "    acc_manhattan.append(accuracy_score(y_test, y_pred_man))\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(k_range, acc_euclidean, label='Euclidean (p=2)')\n",
    "plt.plot(k_range, acc_manhattan, label='Manhattan (p=1)')\n",
    "plt.xlabel(\"Value of k (n_neighbors)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"kNN Accuracy vs k (Euclidean vs Manhattan)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad3060",
   "metadata": {},
   "source": [
    "To assess the effect of hyperparameters on kNN, we evaluated the model using different values of k (from 1 to 19) with two distance metrics: Euclidean (p=2) and Manhattan (p=1). The results, as shown in the figure, indicate that the model achieves its highest accuracy when k=1, particularly with Euclidean distance.\n",
    "\n",
    "Although the highest test accuracy is achieved when k=1 using Euclidean distance, such a low k value may cause the model to overfit the training data. This is because k=1 leads to highly localized decision boundaries that are sensitive to noise and outliers.\n",
    "\n",
    "As k increases, the model becomes more stable and less sensitive to individual samples, but accuracy gradually decreases due to over-smoothing. A trade-off is observed: small k values (e.g., 3 to 5) tend to offer a better balance between capturing local structure and avoiding overfitting.\n",
    "\n",
    "Overall, Euclidean distance performs consistently better than Manhattan distance in this task. A moderate k value such as 5 may offer the best compromise between accuracy and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a10233f",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ac271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_kernel  param_C  param_gamma  mean_f1_score\n",
      "         rbf      0.1         0.01       0.338556\n",
      "         rbf      0.1         0.05       0.338556\n",
      "         rbf      0.1         0.10       0.338556\n",
      "         rbf      0.1         0.50       0.338556\n",
      "         rbf      0.1         1.00       0.338556\n",
      "         rbf      1.0         1.00       0.487531\n",
      "         rbf   1000.0         1.00       0.495709\n",
      "         rbf     10.0         1.00       0.495709\n",
      "         rbf    100.0         1.00       0.495709\n",
      "         rbf     10.0         0.50       0.507466\n",
      "         rbf    100.0         0.10       0.507466\n",
      "         rbf     10.0         0.10       0.507466\n",
      "         rbf     10.0         0.05       0.507466\n",
      "         rbf    100.0         0.50       0.507466\n",
      "         rbf      1.0         0.50       0.507466\n",
      "         rbf      1.0         0.10       0.507466\n",
      "         rbf      1.0         0.05       0.507466\n",
      "         rbf   1000.0         0.05       0.507466\n",
      "         rbf   1000.0         0.10       0.507466\n",
      "         rbf   1000.0         0.50       0.507466\n",
      "         rbf    100.0         0.05       0.507466\n",
      "         rbf      1.0         0.01       0.783299\n",
      "         rbf   1000.0         0.01       0.801416\n",
      "         rbf     10.0         0.01       0.801416\n",
      "         rbf    100.0         0.01       0.801416\n",
      "      linear   1000.0         0.01       0.965009\n",
      "      linear   1000.0         0.05       0.965009\n",
      "      linear    100.0         1.00       0.965009\n",
      "      linear    100.0         0.50       0.965009\n",
      "      linear   1000.0         0.10       0.965009\n",
      "      linear   1000.0         0.50       0.965009\n",
      "      linear    100.0         0.10       0.965009\n",
      "      linear      0.1         0.01       0.965009\n",
      "      linear    100.0         0.01       0.965009\n",
      "      linear      0.1         0.05       0.965009\n",
      "      linear      0.1         0.10       0.965009\n",
      "      linear      0.1         0.50       0.965009\n",
      "      linear      0.1         1.00       0.965009\n",
      "      linear      1.0         0.01       0.965009\n",
      "      linear      1.0         0.05       0.965009\n",
      "      linear    100.0         0.05       0.965009\n",
      "      linear      1.0         0.10       0.965009\n",
      "      linear      1.0         1.00       0.965009\n",
      "      linear     10.0         0.01       0.965009\n",
      "      linear     10.0         0.05       0.965009\n",
      "      linear   1000.0         1.00       0.965009\n",
      "      linear     10.0         0.50       0.965009\n",
      "      linear     10.0         1.00       0.965009\n",
      "      linear      1.0         0.50       0.965009\n",
      "      linear     10.0         0.10       0.965009\n"
     ]
    }
   ],
   "source": [
    "# Task 3(b) SVM find best hyperparameters: 5-fold cross validation\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_full = vectorizer.fit_transform(df_train['Text'])\n",
    "X_test_full = vectorizer.transform(df_test['Text'])\n",
    "\n",
    "y_train = df_train['Category']\n",
    "y_test = df_test['Category']\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [0.01, 0.05, 0.1, 0.5, 1]  # only used for 'rbf'\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(svm, param_grid, scoring='f1_weighted', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_full, y_train)\n",
    "\n",
    "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validated F1 score:\", grid_search.best_score_)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "print(\n",
    "    results[[\"param_kernel\", \"param_C\", \"param_gamma\", \"mean_test_score\"]]\n",
    "    .sort_values(\"mean_test_score\")\n",
    "    .rename(columns={\"mean_test_score\": \"mean_f1_score\"})\n",
    "    .to_string(index=False)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kernel: linear\n",
      "Best C: 0.1\n",
      "Best gamma: 0.01\n",
      "\n",
      "Test F1: 1.0000\n",
      "Test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "best_svm = grid_search.best_estimator_\n",
    "\"\"\"\n",
    "SVC(kernel='linear', C=0.1, gamma = any, random_state=42) obtains an f1 score and accuracy score of 1.0\n",
    "\"\"\"\n",
    "\n",
    "# manual hard-margin rbf\n",
    "# best_svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "# best_svm.fit(X_train_full, y_train)\n",
    "\n",
    "y_pred_best = best_svm.predict(X_test_full)\n",
    "\n",
    "print(\"Best kernel:\", grid_search.best_params_['kernel'])\n",
    "print(\"Best C:\", grid_search.best_params_['C'])\n",
    "if 'gamma' in grid_search.best_params_:\n",
    "    print(\"Best gamma:\", grid_search.best_params_['gamma'])\n",
    "\n",
    "# print(\"Best kernel:\", 'rbf')\n",
    "# print(\"Best C:\", 100)\n",
    "# if 'gamma' in grid_search.best_params_:\n",
    "#     print(\"Best gamma:\", 0.01)\n",
    "\n",
    "print()\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred_best, average='weighted')\n",
    "test_acc = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Test F1: {test_f1:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8df0ae",
   "metadata": {},
   "source": [
    "#### SVM Hyperparameter Tuning Discussion\n",
    "\n",
    "We performed a 5-fold cross-validation to tune the SVM's kernel, C, and gamma parameters. The best cross-validated mean F1 score (0.965) was consistently achieved by the linear kernel with a range of C values. \n",
    "\n",
    "We retrained the SVM with the best hyperparameters (kernel='linear', C=0.1) on the entire training set, then evaluated it on the held-out test set. The resulting F1 score on the test set was 1.0000 and the accuracy was 1.0000\n",
    "\n",
    "This demonstrates that the linear SVM is highly effective for this text classification task, likely due to the high linear separability of the features extracted from the articles. The RBF kernel did not perform as well, suggesting that a non-linear boundary was not needed for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525feac",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "alpha_vals = [0.1 * x for x in range(1, 50)]\n",
    "scores = []\n",
    "\n",
    "for value in alpha_vals:\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(20,), alpha=value, max_iter=100, random_state=42)\n",
    "    score = cross_val_score(classifier, X, y, cv=5, scoring='accuracy')\n",
    "    scores.append(np.mean(score))\n",
    "\n",
    "alpha_index = scores.index(max(scores))\n",
    "best_alpha = alpha_vals[alpha_index]  \n",
    "\n",
    "print(f\"Best alpha value is {best_alpha} with an accuracy of {max(scores):.4f}\")\n",
    "=======\n",
    "# NN code does here\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e74564",
   "metadata": {},
   "source": [
    "## 3(c) Classifier Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bc60b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49b755-2bd3-4058-97a0-5b8cc7566e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score for test data: 0.989010989010989\n",
      "accuracy for test data: 99.05660377358491%\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "all_text = pd.concat([df['Text'],df_test['Text']])\n",
    "final_vectorizer = CountVectorizer().fit(all_text)\n",
    "X = final_vectorizer.transform(df['Text'])\n",
    "final_nb_model = MultinomialNB(alpha = best_alpha)\n",
    "final_nb_model.fit(X,y)\n",
    "X_test = final_vectorizer.transform(df_test['Text'])\n",
    "y_test = df_test['Category']\n",
    "test_prediction = final_nb_model.predict(X_test)\n",
    "test_f1_score = f1_score(y_test, test_prediction, pos_label = label[1])\n",
    "test_accuracy = accuracy_score(y_test, test_prediction)\n",
    "print(f\"f1-score for test data: {test_f1_score}\")\n",
    "print(f\"accuracy for test data: {test_accuracy * 100}%\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38aaa6d",
   "metadata": {},
   "source": [
    "This model gets an F1-score of 0.989 and an accuracy of 99.0566%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c272c",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a371d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.5938\n",
      "Test Accuracy: 0.7547\n"
     ]
    }
   ],
   "source": [
    "best_k = 5\n",
    "best_metric = 'euclidean'\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k, metric=best_metric)\n",
    "knn.fit(X, y)\n",
    "y_pred = knn.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, pos_label = label[1])\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df05dd",
   "metadata": {},
   "source": [
    "For the k-Nearest Neighbors (kNN) classifier, we evaluated multiple values of k and distance metrics to determine the best-performing configuration. Based on testing accuracy and F1 score, the highest test F1 was observed when using Euclidean distance (p=2) with a small value of k, particularly k=1. However, considering the risk of overfitting at k=1, we chose k=5 with Euclidean distance as the best trade-off between performance and generalization.\n",
    "\n",
    "Using this setting (k=5, Euclidean), the model achieved a test F1 score of 0.5938 and accuracy of 0.7547. The decision boundary was relatively smooth, and the model was able to capture local structure in the data while avoiding overfitting. Compared to larger k values, this configuration maintained better class separation and more consistent predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc42dcd",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028aec2",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b><<<<<<< local</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50c6c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kernel: linear\n",
      "Best C: 0.1\n",
      "Best gamma: 0.01\n",
      "\n",
      "Test F1: 1.0000\n",
      "Test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Task 3(c): SVM classifier comparison with best hyperparameters\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "best_svm = grid_search.best_estimator_\n",
    "\"\"\"\n",
    "SVC(kernel='linear', C=0.1, gamma = any, random_state=42) obtains an f1 score and accuracy score of 1.0\n",
    "I'm very confused, therefore the above code has been commented out\n",
    "Feel free to uncomment and test with the grid_search.best_estimator_\n",
    "\"\"\"\n",
    "\n",
    "# manual hard-margin rbf\n",
    "# best_svm = SVC(kernel='rbf', C=100, gamma=0.01, random_state=42)\n",
    "# best_svm.fit(X_train_full, y_train)\n",
    "\n",
    "y_pred_best = best_svm.predict(X_test_full)\n",
    "\n",
    "print(\"Best kernel:\", grid_search.best_params_['kernel'])\n",
    "print(\"Best C:\", grid_search.best_params_['C'])\n",
    "if 'gamma' in grid_search.best_params_:\n",
    "    print(\"Best gamma:\", grid_search.best_params_['gamma'])\n",
    "\n",
    "# print(\"Best kernel:\", 'rbf')\n",
    "# print(\"Best C:\", 100)\n",
    "# if 'gamma' in grid_search.best_params_:\n",
    "#     print(\"Best gamma:\", 0.01)\n",
    "\n",
    "print()\n",
    "\n",
    "test_f1 = f1_score(y_test, y_pred_best, average='weighted')\n",
    "test_acc = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Test F1: {test_f1:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108a4693",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>=======</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c1604cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from previous part we got:\n",
      " Best kernel: linear \n",
      " Best C: 0.1 \n",
      " Best gamma: 0.01 \n",
      " Test F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"from previous part we got:\")\n",
    "print(\" Best kernel: linear \\n Best C: 0.1 \\n Best gamma: 0.01 \\n Test F1: 1.0000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640ebd6",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>>>>>>>> remote</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e4684",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14863684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural net code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174dcac3",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "<<<<<<< local\n",
    "# summary code goes here\n",
    "=======\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ">>>>>>> remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee65b5",
   "metadata": {},
   "source": [
    "# Task Four: Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dde1797",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b><<<<<<< local</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d096d1b",
   "metadata": {},
   "source": [
    "#### SVM Hyperparameter Tuning and Final Evaluation\n",
    "\n",
    "We tried to perform a 5-fold cross-validation to tune the SVM's kernel, C, and gamma parameters. The best cross-validated mean F1 score (0.965) was consistently achieved by the linear kernel with a range of C values. \n",
    "\n",
    "We retrained the SVM with the best hyperparameters (kernel='linear', C=0.1) on the entire training set, then evaluated it on the held-out test set. The resulting F1 score on the test set was 1.0000 and the accuracy was 1.0000\n",
    "\n",
    "This demonstrates that the linear SVM is highly effective for this text classification task, likely due to the high separability of the features extracted from the articles. The RBF kernel did not perform as well, suggesting that a non-linear boundary was not needed for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d4efc-ebfc-4286-88c7-acc342aec998",
   "metadata": {},
   "source": [
    "Task 2(a) discussion\n",
    "\n",
    "The list of the top 20 words that maximise the P(Xw = 1|Y = y)/P(Xw = 1|Y != y) describes the two classes better. The list in (i) only displays words that appear frequently in different categories, which contain many meaningless and commonly used words. These common words will appear in both categories, for example, 'said' appears in both categories in list (i). At the same time, the list in (ii) highlights the probability of words that appear frequently in only one category, while reducing the probability of common words that appear in both categories. Most of the words in list (ii) have marked features of the specific category. Therefore, the list in (ii) describes the two classes better.\n",
    "\n",
    "Task 3(a) discussion for naive bayes\n",
    "\n",
    "For low m (m = 0.1, m = 0.3), the F1 score of training data is very high, and the F1 score of testing data increases rapidly from a relatively low value. When the training data set increases from a very small set, the prediction of the testing data is trending to have increasing accuracy. As the training data set is still very small, it is very easy for the model to make the correct prediction on the training data.\n",
    "For middle m (m from 0.3 to 0.5), the F1 score of training data decreases from a very high value to a relatively high value, and the F1 score of testing data increases more slowly to a relatively high value. As the training data set increases, it has relatively lower accuracy when making predictions on the training data as it tends to be less overfitting on training data as the size of training data set increases, and the accuracy of predictions on test data increases when the size of the training data set increases.\n",
    "For large m, the F1 score of testing data grows very high, and the F1 score of training data is still high, but relatively lower than for small m. The F1 scores for the training data and testing data are similar, which shows that the model gives high accuracy in both the training data and the testing data when m is large.\n",
    "\n",
    "Task 3(b) discussion\n",
    "\n",
    "The hyperparameter alpha is used in Laplace smoothing, it controls how sensitive the model is towards the rare features. A model with a small alpha value will be more sensitive towards rare features. In this question, as the two categories have very different articles, a small alpha value of 0.1 gives the best accuracy in testing.\n",
    "\n",
    "Task 3(c) naive bayes\n",
    "\n",
    "This model gets an F1-score of 0.989 and an accuracy of 99.0566%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad2b11",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>=======</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532f0852",
   "metadata": {},
   "source": [
    "this is distrubuted among the rest of the report as suggested in the assignment specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2266123",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>>>>>>>> remote</b></span>"
   ]
  }
 ],
 "metadata": {
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "jupyter-env",
      "language": "python",
      "name": "python3"
     }
    },
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
     }
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     }
    },
    {
     "key": "language_info",
     "op": "add",
     "value": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
     }
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
